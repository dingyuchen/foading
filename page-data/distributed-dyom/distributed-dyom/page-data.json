{"componentChunkName":"component---node-modules-gatsby-theme-garden-src-templates-local-file-js","path":"/distributed-dyom/distributed-dyom","result":{"data":{"file":{"childMdx":{"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"distributed-systems\"\n  }, \"Distributed Systems\"), mdx(\"p\", null, \"#entry\"), mdx(\"h2\", {\n    \"id\": \"table-of-contents\"\n  }, \"Table of Contents\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"MapReduce\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"[\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"gfs\",\n    \"title\": \"Google File System\"\n  }, \"gfs\"), \"] - Google File System\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Raft\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"[\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"spinnaker\",\n    \"title\": \"Spinnaker\"\n  }, \"spinnaker\"), \"]\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"[\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"aurora\",\n    \"title\": \"Aurora\"\n  }, \"aurora\"), \"]\")), mdx(\"p\", null, \"[\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"crdt\",\n    \"title\": \"Convergent and Commutative Replicated Data Types\"\n  }, \"crdt\"), \"]\"));\n}\n;\nMDXContent.isMDXComponent = true;","outboundReferences":[{"__typename":"Mdx","body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"google-file-system\"\n  }, \"Google File System\"), mdx(\"p\", null, \"[\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"../journal/2021-01-17\",\n    \"title\": \"Sunday, January 17, 2021\"\n  }, \"2021-01-17\"), \"]\"), mdx(\"p\", null, \"#school #paper\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"Original paper referenced \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://pdos.csail.mit.edu/6.824/papers/gfs.pdf\"\n  }, \"here\"))), mdx(\"h2\", {\n    \"id\": \"motivation\"\n  }, \"Motivation\"), mdx(\"p\", null, \"Usage for Google's distributed file system defers from the traditional assumptions in the following ways:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Component failure are the norm rather than the exception.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Files are huge by traditional standards\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Most files are mutated by appending new data rather than overwriting existing data. Random writes within a file are practically non-existent.\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Appending is the focus of performance optimization and atomicity guarantees\")))), mdx(\"h2\", {\n    \"id\": \"design-overview\"\n  }, \"Design Overview\"), mdx(\"h3\", {\n    \"id\": \"assumptions\"\n  }, \"Assumptions\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"System must be able to constantly monitor itself, detect and tolerate and recover from failures on a routine basis.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"System is optimized for large, multi-GB files.\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Small files are supported but not optimized for\"))), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Workload primarily consist of:\", mdx(\"ol\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Large streaming reads\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Small random reads\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Small reads are batched together as large read by performance conscious applications anyway\"))))), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Workload consist of large, sequential writes\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"System must efficiently implement well-defined semantics for multiple clients that concurrently append to the same file.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"High sustained bandwidth is more important than low latency.\")), mdx(\"h2\", {\n    \"id\": \"gfs-api\"\n  }, \"GFS API\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Support the usual \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"create\"), \", \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"delete\"), \", \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"open\"), \", \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"close\"), \", \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"read\"), \", \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"write\"), \".\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Also provides \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"snapshot\"), \" and \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"record append\"), \".\")), mdx(\"h2\", {\n    \"id\": \"architecture\"\n  }, \"Architecture\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Single \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"master\"), \", multiple \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"chunkservers\"), \".\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Accessed by multiple \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"clients\"), \".\")), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"Neither the client nor the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"chunkservers\"), \" caches file data.\")), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"Client \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"do\"), \" cache metadata\")), mdx(\"h3\", {\n    \"id\": \"chunkserver\"\n  }, \"Chunkserver\"), mdx(\"p\", null, \"Files are divided into fixed-size chunks, each chunk is identified by an immutable and gloablly unique \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"64-bit\"), \" \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"chunk handle\"), \".\\nChunks are replicated on different chunkservers (replication level can be determined by user)\"), mdx(\"h3\", {\n    \"id\": \"single-master\"\n  }, \"Single Master\"), mdx(\"p\", null, \"The \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"master\"), \" \"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"maintains all file system metadata\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"controls chunk lease management, garbage collection and chunk migration\")), mdx(\"p\", null, \"Polls \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"chunkservers\"), \" periodically to send instructions and collect state.\"), mdx(\"h4\", {\n    \"id\": \"shadow-masters\"\n  }, \"Shadow Masters\"), mdx(\"p\", null, \"Master state is replicated on other machines in order to achieve fault tolerance and high availability.\\nShadow masters lag slightly and may provide stale metadata, however, it allows clients to perform read operations even when the master is down to enhance read availability.\"), mdx(\"p\", null, \"It polls the master for operation log and applies the same mutations to its internal data structure.\"), mdx(\"h3\", {\n    \"id\": \"chunk-size\"\n  }, \"Chunk Size\"), mdx(\"p\", null, mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"64mb\"), \" is much larger than typical file system block sizes.\"), mdx(\"p\", null, \"Large chunk size pros:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Reduces client's need to interact with the master\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Reduces network overhead by keeping a persistent connection to the chunkserver\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Reduces the size of metadata\")), mdx(\"p\", null, \"Cons:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Small files that consist of only few chunks can become hotspots if many clients are accessing the same file.\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"unlikely since most files are big\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"increase replication factor and stagger batch-queue system.\")))), mdx(\"h3\", {\n    \"id\": \"metadata\"\n  }, \"Metadata\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"File and chunk namespaces\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Mapping from files to chunks\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Locations of each chunk's replicas\")), mdx(\"p\", null, \"Namespaces and mappings are kept persistent by logging mutations to an \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"operation log\"), \".\"), mdx(\"p\", null, \"Locations are requested from the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"chunkservers\"), \" at startup and periodically after. This helps keep the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"master\"), \" in sync\"), mdx(\"h3\", {\n    \"id\": \"operation-log\"\n  }, \"Operation Log\"), mdx(\"p\", null, \"The operation log contains a historical record of critical metadata changes.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Changes are not made visible to clients until metadata changes are made persistent.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Log is replicated on multiple remote \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#shadow-masters\"\n  }, \"machines\"), \" \", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"A mutation to the state is considered committed only after its log record has been flushed to disk locally and on all master replicas.\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Recovery needs only the latest complete checkpoint and subsequent log files.\")), mdx(\"h2\", {\n    \"id\": \"consistency-model\"\n  }, \"Consistency Model\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"A file region is \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"consistent\"), \" if all clients will always see the same data, regardless of which replicas they read from.\")), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"A region is \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"defined\"), \" after a file data mutation if it is consistent and clients will see what the mutation writes in its entirety.\")), mdx(\"p\", null, \"File namespace mutations (creations) are atomic.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Singular successful mutation guarantees file region to be defined and consistent.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Concurrent successful mutations guarantees file region to be undefined but consistent.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"A failed mutation makes the region inconsistent.\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"If a record append fails at any replica, the client retries the operation. GFS only guarantees that the data is written at least once as an atomic unit.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Record prepared by the writer contains extra information like checksums so that its validity can be verified. Reader should handle padding and duplicates.\")))), mdx(\"h2\", {\n    \"id\": \"system-interactions\"\n  }, \"System Interactions\"), mdx(\"p\", null, \"Below I attempt to summarize the interactions during each GFS operation.\"), mdx(\"h3\", {\n    \"id\": \"create\"\n  }, \"Create\"), mdx(\"p\", null, \"Client acquires read-lock along the directory nodes and write-lock for the file being created.\"), mdx(\"p\", null, \"Subsequently client follows the same steps as in \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"#write\"\n  }, \"write\"), \".\"), mdx(\"h3\", {\n    \"id\": \"read\"\n  }, \"Read\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Client requests read operation with file name, chunk index from master.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Master acquires the necessary read-locks, replies client with chunk handle and location.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Client caches chunk handle, requests chunk from \\\"closest\\\" machine.\")), mdx(\"h3\", {\n    \"id\": \"write\"\n  }, \"Write\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Client asks the master which chunkserver holds the current lease for the chunk and the locations of the other replicas.\", mdx(\"ol\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Master grants the lease if no chunkserver is holding the lease\"))), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"The master replies with the identity of the primary and the locations of the other replicas.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"The client pushes the data to all replicas. \"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Client sends a write request to the primary. \"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Primary serializes the mutations and apply it to local state.\", mdx(\"ol\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"If an error occurs at the primary, mutations will not be assigned a serial number and write request will not be forwarded.\"))), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Primary forwards the write request to all secondary replicas.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"The primary replies to the client after replicas report success. Any errors in the replica is also forwarded (request will be considered a failure).\")), mdx(\"h4\", {\n    \"id\": \"chunk-overflow\"\n  }, \"Chunk Overflow\"), mdx(\"p\", null, \"Primary checks to see if appending the record to the current chunk would cause teh chunk to exceed the maximum size.\\nIf so, it pads the chunk to the maximum size, tells secondaries to do the same, and replies to client indicating that the operation should be retried on the next chunk.\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"Record append is restricted to be at most $\\\\frac{1}{4}$ of the maximum chunk size to keep worst-case fragmentation at an acceptable level.\")), mdx(\"h4\", {\n    \"id\": \"dataflow\"\n  }, \"Dataflow\"), mdx(\"p\", null, \"Data is pushed linearly along a chain of chunkservers rather than distributed in some other topology.\\nEach machine's full outbound bandwidth is used to transfer the data as fast as possible rather than divided among multiple recipients.\"), mdx(\"p\", null, \"Each machine forwards the data to the \\\"closest\\\" machine in the network topology that have not received it.\"), mdx(\"h5\", {\n    \"id\": \"pipelining\"\n  }, \"Pipelining\"), mdx(\"p\", null, \"Once a chunkserver receives some data, it starts forwarding immediately. Useful in switched network with full-duplex links.\"), mdx(\"p\", null, \"Without network congestion, the ideal elapsed time for transferring $B$ bytes to $R$ replicas is $B/T + RL$ where $T$ is the network throughput and $L$ is latency to transfer bytes between two machines.\"), mdx(\"h3\", {\n    \"id\": \"delete\"\n  }, \"Delete\"), mdx(\"p\", null, \"Deletion happens lazily and storage space is reclaimed from garbage collection.\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Master logs deletion immediately.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"File is renamed to a hidden name that includes the deletion timestamp.\", mdx(\"ol\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"File is properly removed if it has existed for more than \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"some configurable interval\"), \", during master's regular scan.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Master removes in-memory metadata of hidden file.\")))), mdx(\"p\", null, \"In regular scan of the \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"chunk namespace\"), \", the master identifies orphaned chunks and erases the metadata for those chunks.\"), mdx(\"p\", null, \"In \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"HeartBeat\"), \" messages exchanged with the master, each chunkserver reports a subset of the chunks it has, and the master replies with the identity of all chunks that are no longer present in the master's metadata.\\nThe chunkserver is free to delete its replicas of such chunks.\"), mdx(\"h3\", {\n    \"id\": \"snapshot\"\n  }, \"Snapshot\"), mdx(\"p\", null, \"Snapshots are implemented using standard copy-on-write techniques.\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Master revokes any outstanding leases on the chunks that are about to be snapshot.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Master commits snapshot into its operation log\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Metadata for the source file or directory tree is duplicated.\")), mdx(\"p\", null, \"For write to some snapshot chunk $C$, master notices that the reference count for chunk $C$ is greater than one.\\nIt defers replying to the client request and instead picks a new chunk handle $C'$.\\nIt then asks each chunkserver with $C$ to create copy $C'$ locally.\"), mdx(\"h2\", {\n    \"id\": \"fault-tolerance\"\n  }, \"Fault Tolerance\"), mdx(\"h1\", {\n    \"id\": \"discussion-questions\"\n  }, \"Discussion Questions\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"When does GFS choose \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"write append\"), \" vs \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"record append\"), \"?\", mdx(\"ol\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"write append -> non-concurrent ?\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"record append -> concurrent ?\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Who decides?\"))), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Consider the paper \\\"The Google File System\\\" by Ghemawat et al. Suppose that, at the moment, nobody is writing to the GFS file named\\n\\\"info\\\". Two clients open \\\"info\\\" and read it from start to finish at\\nthe same time. Both clients' cached meta-data information about file\\n\\\"info\\\" is correct and up-to-date. Are the two clients guaranteed to\\nsee the same content? If yes, explain how GFS maintains this\\nguarantee; if no, describe an example scenario in which the clients\\ncould see different content.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://pdos.csail.mit.edu/6.824/quizzes/q18-1.pdf\"\n  }, \"2018 Q1\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://pdos.csail.mit.edu/6.824/quizzes/q17-1.pdf\"\n  }, \"2017 Q2.2\"))));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"61ee9891-99e9-55f0-9c1a-8851f9082b98","fields":{"slug":"/distributed-dyom/gfs","title":"Google File System"}}},{"__typename":"Mdx","body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"spinnaker\"\n  }, \"Spinnaker\"), mdx(\"p\", null, \"Spinnaker is a datastore.\"), mdx(\"p\", null, \"It features key-based range partitioning, 3-way replication, and a transactional get-put API with the option to choose either strong or timeline consistency on reads.\"), mdx(\"h2\", {\n    \"id\": \"limitations-master-slave-replication\"\n  }, \"Limitations Master-Slave Replication\"), mdx(\"p\", null, \"Loss of either master or slave can result in permanent data loss.\"), mdx(\"p\", null, \"For 3 replicas, more complicated failure sequences can be possible.\"), mdx(\"h2\", {\n    \"id\": \"consistency\"\n  }, \"Consistency\"), mdx(\"p\", null, \"Strong consistency\\n: guarantees that all replicas appear identical to applications\"), mdx(\"p\", null, \"Timeline consistency\\n: allows potentially stale data to be return in exchange for better performance.\"), mdx(\"p\", null, \"[\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"cap-theorem\",\n    \"title\": \"CAP Theorem\"\n  }, \"cap-theorem\"), \"]\"), mdx(\"p\", null, \"Within a single datacenter where network partitions are rar, opting for strong consistency and availability is a better design choice.\"), mdx(\"h2\", {\n    \"id\": \"data-model-and-api\"\n  }, \"Data Model and API\"), mdx(\"p\", null, \"get(key, colname, consistent)\\n: Read a column value and its version number from a row. The setting of the 'consistent' flag is used to choose the consistency level.\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"Setting it to \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"true\"), \" chooses strong consistency, and the latest value is always returned.\"), mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"Setting it to \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"false\"), \" chooses timeline consistency, and a possibly stale value is return in exchange for better performance.\")), mdx(\"p\", null, \"put(key, colname, colvalue)\\n: Insert a column value into a row\"), mdx(\"p\", null, \"delete(key, colname)\\n: Delete a column from a row\"), mdx(\"p\", null, \"conditionalPut(key, colname, value, v)\\n: Insert a new column value into a row only if the column's current version number is equal to 'v'. Otherwise, an error is returned.\"), mdx(\"p\", null, \"conditionalDelete(key, colname, v)\\n: Like \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"conditionalPut\"), \" but for delete\"), mdx(\"p\", null, \"Version numbers are monotonically increasing integers that are managed by Spinnaker and exposed through its get API\"), mdx(\"h2\", {\n    \"id\": \"architecture\"\n  }, \"Architecture\"), mdx(\"p\", null, \"Each node is assigned a base key range which is replicated on the next $N - 1$ nodes.\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"$N$ is a replication setting\")), mdx(\"p\", null, \"Each group of nodes involved in replicating a key range is denoted as a \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"cohort\"), \".\"), mdx(\"h3\", {\n    \"id\": \"node-architecture\"\n  }, \"Node Architecture\"), mdx(\"h2\", {\n    \"id\": \"replication-protocol\"\n  }, \"Replication Protocol\"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"732ce9ac-1e2a-57cd-b821-c600f33efbc5","fields":{"slug":"/distributed-dyom/spinnaker","title":"Spinnaker"}}},{"__typename":"Mdx","body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"aurora\"\n  }, \"Aurora\"), mdx(\"h2\", {\n    \"id\": \"introduction\"\n  }, \"Introduction\"), mdx(\"p\", null, \"Aurora is a relational database service for OLTP workloads offered as part of AmazonWeb Services.\"), mdx(\"p\", null, \"Checkpointing and dirty page writing can reduce the penalty of blocking reads.\"), mdx(\"p\", null, \"dirty page writing\\n: writing into a cache, that only becomes reflected on persistent storage when the buffer is flushed.\"), mdx(\"p\", null, \"Transaction commits are intolerant of failure.\\nThey are also high latency, as high scale systems are distributed across multiple data centers.\\n(140ms for nodes across the ocean)\"), mdx(\"h3\", {\n    \"id\": \"core-idea\"\n  }, \"Core idea\"), mdx(\"p\", null, \"Redo log (something similar to write-ahead logs)\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"protect the database from performance variance and transient or permanent failures at either the networking or storage tiers.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"By only writing redo log records to storage, we are able to reduce network IOPS by an order of magnitude.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Move some of the most complex and critical functions (backup and redo recovery) from one-time expensive operations in the database engine to continuous asynchronous operations amortized across a large distributed fleet.\")), mdx(\"h2\", {\n    \"id\": \"durability-at-scale\"\n  }, \"Durability at scale\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"Data, once written, can be read.\")), mdx(\"h3\", {\n    \"id\": \"replication\"\n  }, \"Replication\"), mdx(\"p\", null, \"Nodes need to be replicated on some level to achieve resiliency to failure.\"), mdx(\"p\", null, \"Quorum must obey 2 rules\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Each read must be aware of the most recent write.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Each write must be aware of the most recent write to avoid conflicting writes.\")), mdx(\"p\", null, \"Availability Zone (AZ) is a subset of a Region that is connected to other AZs in the region through low latency links but is isolated for most faults, including power, networking, software deployments, flooding, etc.\"), mdx(\"p\", null, \"Quorums need to tolerate an AZ failure as well as concurrently occurring background noise failures.\"), mdx(\"p\", null, \"Chosen design point of tolerating\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"losing an entire AZ and one additional node (AZ + 1) without losing data, \"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"and losing an entire AZ without impacting the ability to write data.\")), mdx(\"p\", null, \"Ensuring read quorum enables us to rebuild write quorum by adding additional replica copies.\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"Can still achieve healing from a 3-node failure.\")), mdx(\"p\", null, \"Partition the database volume into small fixed size segments, each replicated into Protection Groups (PG).\"), mdx(\"p\", null, \"Segments are now our unit of independent of background noise failure and repair\\nWe would eed to see two such failures in the same 10 second window plus a failure of an AZ not containing either of these two independent failures to lose quorum.\"), mdx(\"h3\", {\n    \"id\": \"operational-advantages-of-resilience\"\n  }, \"Operational Advantages of Resilience\"), mdx(\"p\", null, \"Treat nodes as \\\"bad\\\" and make use of repair mechanism.\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"This allows us to use agile methodologies and rapid deployments in our storage service.\")), mdx(\"h2\", {\n    \"id\": \"the-log-is-the-database\"\n  }, \"The Log is the Database\"), mdx(\"p\", null, \"Model of 6 ways segmentation and 4/6 quorum results in untenable performance for a traditional database like MySQL that generates many different actual I/Os for each application write.\"), mdx(\"p\", null, \"Types of data that the engine needs to write:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"The redo logs\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Binary (statement) log that is archived to S# in order to support point-in-time restores \"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"The modified data pages\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Seoncd temporary write of the data page (double-write) to prevent torn pages\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Metadata (FRM) files\")), mdx(\"p\", null, \"Durable redo record application happens at the storage tier, continuously, asynchronously, and distributed across the fleet.\\nAny read request for a data page may require some redo records to be applied if the page is not current.\\nCrash recovery is spread across all normal foreground processing.\"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"68843cbe-51c8-5cac-9219-4fbf5948e189","fields":{"slug":"/distributed-dyom/aurora","title":"Aurora"}}},{"__typename":"Mdx","body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"convergent-and-commutative-replicated-data-types\"\n  }, \"Convergent and Commutative Replicated Data Types\"), mdx(\"p\", null, \"Does not require synchronization.\"), mdx(\"p\", null, \"It is extremely scalable and is fault-tolerant.\"), mdx(\"p\", null, \"Quiescent consistent\"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"b4e2950e-4d89-5b1c-bf48-7eb1eea95a53","fields":{"slug":"/distributed-dyom/crdt","title":"Convergent and Commutative Replicated Data Types"}}}],"inboundReferences":[{"__typename":"Mdx","body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"bubble-foader\"\n  }, \"Bubble Foader\"), mdx(\"p\", null, \"#entry\"), mdx(\"p\", null, \"\\uD83D\\uDC4B Welcome to my Foam Knowledge Base!\"), mdx(\"h2\", {\n    \"id\": \"navigation\"\n  }, \"Navigation\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"dingyuchen.github.io\"\n  }, \"blog\"), \" - This is where I keep my blog\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"[\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"inbox\",\n    \"title\": \"Inbox\"\n  }, \"inbox\"), \"] - a place to write down quick notes to be categorised later\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"[\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"todo\",\n    \"title\": \"Todo\"\n  }, \"todo\"), \"] - a place to keep track of things I want/need to do\")), mdx(\"h3\", {\n    \"id\": \"modules\"\n  }, \"Modules\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"[\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"cs5330/module-5330\",\n    \"title\": \"Randomized Algorithms\"\n  }, \"module-5330\"), \"] - CS5330 Randomized Algorithms\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"[\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"distributed-dyom/distributed-dyom\",\n    \"title\": \"Distributed Systems\"\n  }, \"distributed-dyom\"), \"] - DYOM Distributed Systems\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"[\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"st2131/module-2131\",\n    \"title\": \"Probability\"\n  }, \"module-2131\"), \"] - ST2131 Probability\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"[\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"ma3110/module-ma3110\",\n    \"title\": \"Mathematical Analysis 2\"\n  }, \"module-ma3110\"), \"] - MA3110 Mathematical Analysis 2\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"[\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"ma2101/module-ma2101\",\n    \"title\": \"Linear Algebra 2\"\n  }, \"module-ma2101\"), \"] - MA2101 Linear Algebra 2\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"[\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"ma2104/module-ma2104\",\n    \"title\": \"Multivariable Calculus\"\n  }, \"module-ma2104\"), \"] - MA2104 Multivariable Calculus\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"[\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"ma3252/module-ma3252\",\n    \"title\": \"Linear and Network Optimization\"\n  }, \"module-ma3252\"), \"] - MA3252 Linear and Network Optimization\")), mdx(\"h3\", {\n    \"id\": \"other-collections\"\n  }, \"Other Collections\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"[\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"misc/misc\",\n    \"title\": \"Miscellaneous\"\n  }, \"misc\"), \"]\")), mdx(\"h2\", {\n    \"id\": \"making-your-own\"\n  }, \"Making your own\"), mdx(\"p\", null, \"This documentation assumes that you have a GitHub account and have \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://code.visualstudio.com/\"\n  }, \"Visual Studio Code\"), \" installed on your Linux/MacOS/Windows machine.\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"If you haven't yet, browse over to the main \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://foambubble.github.io/foam\"\n  }, \"Foam documentation workspace\"), \" to get an idea of what Foam is and how to use it.\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Press \\\"Use this template\\\" button at \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/mathieudutour/foam-gatsby-template/generate\"\n  }, \"foam-gatsby-template\"), \" to fork it to your own GitHub account. If you want to keep your thoughts to yourself, remember to set the repository private.\"), mdx(\"ol\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"This creates a gatsby template instead of the vanilla one used by Foam. It supports backlinking and graph out of the box.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Unfortunately, it does not allow nested subfolders (pending PR merge) and latex.\"))), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://help.github.com/en/github/creating-cloning-and-archiving-repositories/cloning-a-repository\"\n  }, \"Clone the repository to your local machine\"), \" and open it in VS Code.\"), mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Open the repository as a folder using the \", mdx(\"inlineCode\", {\n    parentName: \"em\"\n  }, \"File > Open...\"), \" menu item.\"))), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"When prompted to install recommended extensions, click \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Install all\"), \" (or \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Show Recommendations\"), \" if you want to review and install them one by one)\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Open \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"_layouts/gatsby-config.js\"\n  }, \"_layouts/gatsby-config.js\"), \" and edit the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"pathPrefix\"), \" to be the name of the repository.\"))), mdx(\"p\", null, \"After setting up the repository, head to [\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"getting-started\",\n    \"title\": \"Getting Started\"\n  }, \"getting-started\"), \"] to get familiar with your new knowledge base!\"), mdx(\"p\", null, \"To learn more about how to use \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Foam\"), \", read the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://foambubble.github.io/foam/recipes/recipes\"\n  }, \"Recipes\"), \" bubbles of the Foam documentation workspace.\"), mdx(\"p\", null, \"And remember that you can always join our  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://discord.gg/HV2tn2FpEk\"\n  }, \"Foam community on Discord\"), \"!\"));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"b97941cc-9f81-5bf4-85d9-dcd0172036fd","fields":{"slug":"/readme","title":"Bubble Foader"}}}]},"fields":{"slug":"/distributed-dyom/distributed-dyom","title":"Distributed Systems"}}},"pageContext":{"id":"14f7242e-6dbb-57e6-81a6-d73cb80db295"}},"staticQueryHashes":["2098632890","2221750479","2468095761"]}